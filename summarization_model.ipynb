{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries"
      ],
      "metadata": {
        "id": "2O_eiVCIIW__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQEGdVJnIWOv"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain -qU langchain-groq langchain-text-splitters tiktoken langchain_community pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required packages"
      ],
      "metadata": {
        "id": "iJKAjtguIau5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import tiktoken\n",
        "import requests\n",
        "from google.colab import files\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "GsAHjQtTIdIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "set GROQ API key"
      ],
      "metadata": {
        "id": "x41o4ir2IevU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GROQ_API_KEY'] = \"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\""
      ],
      "metadata": {
        "id": "r7fgyEl1IhwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model"
      ],
      "metadata": {
        "id": "UG4hPVOqIhE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "VEeL2Du-Imk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload PDF"
      ],
      "metadata": {
        "id": "eaiGmtoMIou-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "pdf_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "uBlkDreAIobJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load PDF and clean content"
      ],
      "metadata": {
        "id": "O6cZ6DUmIt6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(pdf_path)\n",
        "data = loader.load()\n",
        "data[0].page_content = re.sub(r\"\\n\\n+\", \"\\n\", data[0].page_content)"
      ],
      "metadata": {
        "id": "UQgDYmU9Itkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token estimation"
      ],
      "metadata": {
        "id": "ZHV3aFj4Iz-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Estimated tokens: {int(len(data[0].page_content)* 4 / 3)}\")"
      ],
      "metadata": {
        "id": "RJEeBVFVI0yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into chunks"
      ],
      "metadata": {
        "id": "Gsp-BQ6CI27n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 2000\n",
        "chunk_overlap = 100\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
        ")\n",
        "\n",
        "splits = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "eLNrLX64I41R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map prompt"
      ],
      "metadata": {
        "id": "GtjQ4LUAI7Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_prompt = PromptTemplate(\n",
        "    template=\"\"\"Write a concise summary of the following text. The summary should be a list of bullet points. The summary cannot be more than 5 bullet points. The text is:\n",
        "{text}\n",
        "\n",
        "Summary: \"\"\",\n",
        "    input_variables=['text']\n",
        ")"
      ],
      "metadata": {
        "id": "FM3AFtl7I9GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarize each chunk"
      ],
      "metadata": {
        "id": "DOuCjCHsI_CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "summaries = []\n",
        "for split in tqdm(splits):\n",
        "    try:\n",
        "        response = model.predict(map_prompt.format(text=split.page_content))\n",
        "        summaries.append(response)\n",
        "    except Exception:\n",
        "        summaries.append(\"Error\")"
      ],
      "metadata": {
        "id": "pCJ6SMdBJBDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group summarization for reduction"
      ],
      "metadata": {
        "id": "RgnfxqAuJD4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_summaries(summaries, max_summaries):\n",
        "  groups = []\n",
        "  current_group = []\n",
        "  for summary in summaries:\n",
        "    current_group.append(summary)\n",
        "    if len(current_group) >= max_summaries:\n",
        "      groups.append(current_group)\n",
        "      current_group = []\n",
        "  if current_group:\n",
        "    groups.append(current_group)\n",
        "  return groups\n",
        "\n",
        "groups = group_summaries(summaries, 10)"
      ],
      "metadata": {
        "id": "GdIpYq9pJF02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine prompt for mid level summaries"
      ],
      "metadata": {
        "id": "FhQglDbEJJDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combine_prompt = PromptTemplate(\n",
        "    template= \"\"\"The following is set of bullet-point summaries:\n",
        "{docs}\n",
        "Take these and distill it into a consolidated bullet-point summary of the main themes. Remove the bullet points that are not relevant to the whole text. The consolidated summary cannot be more than 7 bullet points.\n",
        "Helpful Answer: \"\"\",\n",
        "    input_variables=['docs']\n",
        ")"
      ],
      "metadata": {
        "id": "fzru2clDJLDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine group summaries iteratively"
      ],
      "metadata": {
        "id": "S0ftkk7eJNVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while len(groups) > 1:\n",
        "  new_summaries = []\n",
        "  for group in groups:\n",
        "    response = model.invoke(combine_prompt.format(docs=\"\\n\".join(group)))\n",
        "    new_summaries.append(response.content)\n",
        "  groups = group_summaries(new_summaries, 10)"
      ],
      "metadata": {
        "id": "5ViF1g86JPIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups[0][0]"
      ],
      "metadata": {
        "id": "PHWj6leRJS7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final reduction prompt"
      ],
      "metadata": {
        "id": "6qyN8qDFJQ-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "You are an expert summarizer.\n",
        "\n",
        "Below are multiple summaries of different sections of a document. Please combine them into a single, cohesive paragraph summary. Make sure the final summary is **15 complete sentences**, written in a fluent and readable academic tone. Do not use bullet points.\n",
        "\n",
        "Summaries:\n",
        "{docs}\n",
        "\n",
        "Final Summary:\n",
        "\"\"\",\n",
        "    input_variables=['docs']\n",
        ")\n",
        "response = model.invoke(reduce_prompt.format(docs=\"\\n\".join(groups[0])))\n",
        "final_summary = response.content"
      ],
      "metadata": {
        "id": "n_GfeRC3JWs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final summary"
      ],
      "metadata": {
        "id": "mGMP_06qJZJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "print(\"\\nFinal Summary:\\n\")\n",
        "print(textwrap.fill(final_summary, width=200))"
      ],
      "metadata": {
        "id": "qVIb4oueJaGd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}